{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a7a675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\46737\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Generate some random data\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=3, random_state=42)\n",
    "\n",
    "# Binarize the output labels\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = X[:800], X[800:]\n",
    "y_train, y_test = y_bin[:800], y_bin[800:]\n",
    "\n",
    "# Create and train the ANN classifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the probabilities for each class\n",
    "y_scores = clf.predict_proba(X_test)\n",
    "\n",
    "# Compute the ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(y_bin.shape[1]):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_scores.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot the ROC curves for each class\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]))\n",
    "for i in range(y_bin.shape[1]):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3a6c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418200fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\46737\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (20.9)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "Successfully installed keras-2.10.0\n",
      "Requirement already satisfied: keras in c:\\users\\46737\\anaconda3\\lib\\site-packages (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce457f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d77bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b7c4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: theano in c:\\users\\46737\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from theano) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from theano) (1.20.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\46737\\anaconda3\\lib\\site-packages (from theano) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install theano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bd4d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.43111401\n",
      "Iteration 2, loss = 1.29673473\n",
      "Iteration 3, loss = 1.19663354\n",
      "Iteration 4, loss = 1.12707804\n",
      "Iteration 5, loss = 1.06781525\n",
      "Iteration 6, loss = 1.01607612\n",
      "Iteration 7, loss = 0.96787878\n",
      "Iteration 8, loss = 0.92349768\n",
      "Iteration 9, loss = 0.88195120\n",
      "Iteration 10, loss = 0.84174376\n",
      "Iteration 11, loss = 0.80759453\n",
      "Iteration 12, loss = 0.77409543\n",
      "Iteration 13, loss = 0.74584586\n",
      "Iteration 14, loss = 0.71776885\n",
      "Iteration 15, loss = 0.69566132\n",
      "Iteration 16, loss = 0.67668049\n",
      "Iteration 17, loss = 0.66149941\n",
      "Iteration 18, loss = 0.64451370\n",
      "Iteration 19, loss = 0.62958016\n",
      "Iteration 20, loss = 0.61953190\n",
      "Iteration 21, loss = 0.60837827\n",
      "Iteration 22, loss = 0.60065445\n",
      "Iteration 23, loss = 0.59358425\n",
      "Iteration 24, loss = 0.58724997\n",
      "Iteration 25, loss = 0.58061820\n",
      "Iteration 26, loss = 0.57432821\n",
      "Iteration 27, loss = 0.56788863\n",
      "Iteration 28, loss = 0.56162066\n",
      "Iteration 29, loss = 0.55479912\n",
      "Iteration 30, loss = 0.54821052\n",
      "Iteration 31, loss = 0.54108331\n",
      "Iteration 32, loss = 0.53393400\n",
      "Iteration 33, loss = 0.52703256\n",
      "Iteration 34, loss = 0.51980627\n",
      "Iteration 35, loss = 0.51429375\n",
      "Iteration 36, loss = 0.50801963\n",
      "Iteration 37, loss = 0.50116145\n",
      "Iteration 38, loss = 0.49486449\n",
      "Iteration 39, loss = 0.48830874\n",
      "Iteration 40, loss = 0.48307826\n",
      "Iteration 41, loss = 0.47611708\n",
      "Iteration 42, loss = 0.46994849\n",
      "Iteration 43, loss = 0.46503683\n",
      "Iteration 44, loss = 0.45954887\n",
      "Iteration 45, loss = 0.45471871\n",
      "Iteration 46, loss = 0.44907687\n",
      "Iteration 47, loss = 0.44421453\n",
      "Iteration 48, loss = 0.44111652\n",
      "Iteration 49, loss = 0.43794179\n",
      "Iteration 50, loss = 0.43399415\n",
      "Iteration 51, loss = 0.42986532\n",
      "Iteration 52, loss = 0.42603835\n",
      "Iteration 53, loss = 0.42346890\n",
      "Iteration 54, loss = 0.42030138\n",
      "Iteration 55, loss = 0.41682802\n",
      "Iteration 56, loss = 0.41329543\n",
      "Iteration 57, loss = 0.40959907\n",
      "Iteration 58, loss = 0.40685617\n",
      "Iteration 59, loss = 0.40386587\n",
      "Iteration 60, loss = 0.40147512\n",
      "Iteration 61, loss = 0.39867784\n",
      "Iteration 62, loss = 0.39652736\n",
      "Iteration 63, loss = 0.39445651\n",
      "Iteration 64, loss = 0.39150797\n",
      "Iteration 65, loss = 0.39041125\n",
      "Iteration 66, loss = 0.38902225\n",
      "Iteration 67, loss = 0.38785665\n",
      "Iteration 68, loss = 0.38538047\n",
      "Iteration 69, loss = 0.38281973\n",
      "Iteration 70, loss = 0.38108958\n",
      "Iteration 71, loss = 0.38084985\n",
      "Iteration 72, loss = 0.37963137\n",
      "Iteration 73, loss = 0.37842210\n",
      "Iteration 74, loss = 0.37658484\n",
      "Iteration 75, loss = 0.37509411\n",
      "Iteration 76, loss = 0.37353792\n",
      "Iteration 77, loss = 0.37258408\n",
      "Iteration 78, loss = 0.37103400\n",
      "Iteration 79, loss = 0.37031862\n",
      "Iteration 80, loss = 0.36840833\n",
      "Iteration 81, loss = 0.36766317\n",
      "Iteration 82, loss = 0.36707743\n",
      "Iteration 83, loss = 0.36560914\n",
      "Iteration 84, loss = 0.36389670\n",
      "Iteration 85, loss = 0.36254419\n",
      "Iteration 86, loss = 0.36133104\n",
      "Iteration 87, loss = 0.35988308\n",
      "Iteration 88, loss = 0.35880457\n",
      "Iteration 89, loss = 0.35773579\n",
      "Iteration 90, loss = 0.35697618\n",
      "Iteration 91, loss = 0.35645720\n",
      "Iteration 92, loss = 0.35587685\n",
      "Iteration 93, loss = 0.35409779\n",
      "Iteration 94, loss = 0.35290134\n",
      "Iteration 95, loss = 0.35167874\n",
      "Iteration 96, loss = 0.35051541\n",
      "Iteration 97, loss = 0.34947120\n",
      "Iteration 98, loss = 0.34794211\n",
      "Iteration 99, loss = 0.34664535\n",
      "Iteration 100, loss = 0.34568454\n",
      "Iteration 101, loss = 0.34509151\n",
      "Iteration 102, loss = 0.34442969\n",
      "Iteration 103, loss = 0.34408608\n",
      "Iteration 104, loss = 0.34248711\n",
      "Iteration 105, loss = 0.34091408\n",
      "Iteration 106, loss = 0.33842730\n",
      "Iteration 107, loss = 0.33656183\n",
      "Iteration 108, loss = 0.33661415\n",
      "Iteration 109, loss = 0.33492711\n",
      "Iteration 110, loss = 0.32868137\n",
      "Iteration 111, loss = 0.32495930\n",
      "Iteration 112, loss = 0.32289144\n",
      "Iteration 113, loss = 0.32200196\n",
      "Iteration 114, loss = 0.31911875\n",
      "Iteration 115, loss = 0.31487410\n",
      "Iteration 116, loss = 0.31210266\n",
      "Iteration 117, loss = 0.31093483\n",
      "Iteration 118, loss = 0.31011883\n",
      "Iteration 119, loss = 0.30718171\n",
      "Iteration 120, loss = 0.30411594\n",
      "Iteration 121, loss = 0.30412042\n",
      "Iteration 122, loss = 0.30232879\n",
      "Iteration 123, loss = 0.30081065\n",
      "Iteration 124, loss = 0.29739509\n",
      "Iteration 125, loss = 0.29498234\n",
      "Iteration 126, loss = 0.29375127\n",
      "Iteration 127, loss = 0.29271409\n",
      "Iteration 128, loss = 0.29172700\n",
      "Iteration 129, loss = 0.28996414\n",
      "Iteration 130, loss = 0.28713399\n",
      "Iteration 131, loss = 0.28705418\n",
      "Iteration 132, loss = 0.28681048\n",
      "Iteration 133, loss = 0.28374277\n",
      "Iteration 134, loss = 0.28122204\n",
      "Iteration 135, loss = 0.27946776\n",
      "Iteration 136, loss = 0.27755797\n",
      "Iteration 137, loss = 0.27667970\n",
      "Iteration 138, loss = 0.27550486\n",
      "Iteration 139, loss = 0.27286438\n",
      "Iteration 140, loss = 0.27245897\n",
      "Iteration 141, loss = 0.27050581\n",
      "Iteration 142, loss = 0.26846679\n",
      "Iteration 143, loss = 0.26647849\n",
      "Iteration 144, loss = 0.26523454\n",
      "Iteration 145, loss = 0.26407268\n",
      "Iteration 146, loss = 0.26200049\n",
      "Iteration 147, loss = 0.26068061\n",
      "Iteration 148, loss = 0.26028021\n",
      "Iteration 149, loss = 0.26023864\n",
      "Iteration 150, loss = 0.25623571\n",
      "Iteration 151, loss = 0.25430874\n",
      "Iteration 152, loss = 0.25444924\n",
      "Iteration 153, loss = 0.25429244\n",
      "Iteration 154, loss = 0.25237736\n",
      "Iteration 155, loss = 0.24951970\n",
      "Iteration 156, loss = 0.24871189\n",
      "Iteration 157, loss = 0.24720915\n",
      "Iteration 158, loss = 0.24598788\n",
      "Iteration 159, loss = 0.24588546\n",
      "Iteration 160, loss = 0.24690070\n",
      "Iteration 161, loss = 0.24460528\n",
      "Iteration 162, loss = 0.24278748\n",
      "Iteration 163, loss = 0.24329661\n",
      "Iteration 164, loss = 0.24445945\n",
      "Iteration 165, loss = 0.24302916\n",
      "Iteration 166, loss = 0.24034822\n",
      "Iteration 167, loss = 0.23857298\n",
      "Iteration 168, loss = 0.23784114\n",
      "Iteration 169, loss = 0.23666286\n",
      "Iteration 170, loss = 0.23613470\n",
      "Iteration 171, loss = 0.23698341\n",
      "Iteration 172, loss = 0.23556200\n",
      "Iteration 173, loss = 0.23352985\n",
      "Iteration 174, loss = 0.23194250\n",
      "Iteration 175, loss = 0.23124792\n",
      "Iteration 176, loss = 0.22915797\n",
      "Iteration 177, loss = 0.22811991\n",
      "Iteration 178, loss = 0.22650514\n",
      "Iteration 179, loss = 0.22679516\n",
      "Iteration 180, loss = 0.22650456\n",
      "Iteration 181, loss = 0.22529810\n",
      "Iteration 182, loss = 0.22351411\n",
      "Iteration 183, loss = 0.22267213\n",
      "Iteration 184, loss = 0.22347553\n",
      "Iteration 185, loss = 0.22340770\n",
      "Iteration 186, loss = 0.22037668\n",
      "Iteration 187, loss = 0.21911586\n",
      "Iteration 188, loss = 0.22453181\n",
      "Iteration 189, loss = 0.22561105\n",
      "Iteration 190, loss = 0.21963409\n",
      "Iteration 191, loss = 0.21751909\n",
      "Iteration 192, loss = 0.21874923\n",
      "Iteration 193, loss = 0.21812131\n",
      "Iteration 194, loss = 0.21464336\n",
      "Iteration 195, loss = 0.21542646\n",
      "Iteration 196, loss = 0.21793862\n",
      "Iteration 197, loss = 0.21911380\n",
      "Iteration 198, loss = 0.21498075\n",
      "Iteration 199, loss = 0.21462010\n",
      "Iteration 200, loss = 0.21442688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\46737\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import theano\n",
    "import keras\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "churn_data_encoded = pd.read_csv(\"ogithreeCat.csv\")\n",
    "X = churn_data_encoded.drop(['lastFUBGrade'],axis=1)\n",
    "y = churn_data_encoded.lastFUBGrade\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "input_shape = X_train.shape[1]\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create model object\n",
    "clf = MLPClassifier(hidden_layer_sizes=(6,5),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.01)\n",
    "\n",
    "# Fit data onto the model\n",
    "clf.fit(X_train_smtom, y_train_smtom)\n",
    "ypred=clf.predict(X_test)\n",
    "\n",
    "# Import accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calcuate accuracy\n",
    "accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a322b69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'TrackableSaver'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e90aa225e877>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# input shape is (features,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"Creates a `Sequential` model instance.\n\u001b[1;32m--> 107\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m           \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0mto\u001b[0m \u001b[0madd\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# override compile with custom logic.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;31m# This is True for Sequential networks and Functional networks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msaver_with_op_caching\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   3064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'TrackableSaver'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import theano\n",
    "import keras\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "churn_data_encoded = pd.read_csv(\"ogithreeCat.csv\")\n",
    "X = churn_data_encoded.drop(['lastFUBGrade'],axis=1)\n",
    "y = churn_data_encoded.lastFUBGrade\n",
    "X = np.array(X)\n",
    "nsp_classes = y.unique()\n",
    "\n",
    "# label encoder y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y = np_utils.to_categorical(y)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler=StandardScaler()\n",
    "X=Scaler.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # input shape is (features,)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True) # important - otherwise you just return the last weigths...\n",
    "\n",
    "# now we just update our model fit call\n",
    "\n",
    "\n",
    "history=model.fit(X_train, y_train,\n",
    "                    callbacks=[es],\n",
    "                    epochs=8000000, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "y_pred = model.predict(X_test)\n",
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X) # see how the model did!\n",
    "print(preds[0]) # i'm spreading that prediction across three nodes and they sum to 1\n",
    "print(np.sum(preds[0])) # sum it up! Should be 1\n",
    "## [9.9999988e-01 1.3509347e-07 6.7064638e-16]\n",
    "## 1.0\n",
    "\n",
    "# Almost a perfect prediction\n",
    "# actual is left, predicted is top\n",
    "# names can be found by inspecting Y\n",
    "matrix = confusion_matrix(y.argmax(axis=1), preds.argmax(axis=1))\n",
    "matrix\n",
    "## array([[50,  0,  0],\n",
    "##        [ 0, 46,  4],\n",
    "##        [ 0,  1, 49]])\n",
    "\n",
    "\n",
    "# more detail on how well things were predicted\n",
    "print(classification_report(y.argmax(axis=1), preds.argmax(axis=1)))\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Learn to predict each class against the other\n",
    "\n",
    "\n",
    "n_classes = 3 # number of class\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "plt.figure()\n",
    "lw = 2 # line_width\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]))\n",
    "for i in range(y_bin.shape[1]):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curve for ANN classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dcf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with smotomek\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import theano\n",
    "import keras\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "churn_data_encoded = pd.read_csv(\"ogithreeCat.csv\")\n",
    "X = churn_data_encoded.drop(['lastFUBGrade'],axis=1)\n",
    "Y = churn_data_encoded.lastFUBGrade\n",
    "X = np.array(X)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # input shape is (features,)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True) # important - otherwise you just return the last weigths...\n",
    "\n",
    "# now we just update our model fit call\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample(X, dummy_y)\n",
    "\n",
    "history = model.fit(X_train_smtom, y_train_smtom,\n",
    "                    callbacks=[es],\n",
    "                    epochs=8000000, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X) # see how the model did!\n",
    "print(preds[0]) # i'm spreading that prediction across three nodes and they sum to 1\n",
    "print(np.sum(preds[0])) # sum it up! Should be 1\n",
    "## [9.9999988e-01 1.3509347e-07 6.7064638e-16]\n",
    "## 1.0\n",
    "\n",
    "# Almost a perfect prediction\n",
    "# actual is left, predicted is top\n",
    "# names can be found by inspecting Y\n",
    "matrix = confusion_matrix(dummy_y.argmax(axis=1), preds.argmax(axis=1))\n",
    "matrix\n",
    "## array([[50,  0,  0],\n",
    "##        [ 0, 46,  4],\n",
    "##        [ 0,  1, 49]])\n",
    "\n",
    "\n",
    "# more detail on how well things were predicted\n",
    "print(classification_report(dummy_y.argmax(axis=1), preds.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc216870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import theano\n",
    "import keras\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "churn_data_encoded = pd.read_csv(\"ogithreeCat.csv\")\n",
    "X = churn_data_encoded.drop(['lastFUBGrade'],axis=1)\n",
    "y = churn_data_encoded.lastFUBGrade\n",
    "X = np.array(X)\n",
    "nsp_classes = y.unique()\n",
    "\n",
    "# label encoder y\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y = np_utils.to_categorical(y)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler=StandardScaler()\n",
    "X=Scaler.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # input shape is (features,)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=10, \n",
    "                                   restore_best_weights=True) # important - otherwise you just return the last weigths...\n",
    "\n",
    "# now we just update our model fit call\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample(X, y)\n",
    "\n",
    "history=model.fit(X_train_smtom, y_train_smtom,\n",
    "                    callbacks=[es],\n",
    "                    epochs=8000000, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "y_pred = model.predict(X_test)\n",
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model.predict(X) # see how the model did!\n",
    "print(preds[0]) # i'm spreading that prediction across three nodes and they sum to 1\n",
    "print(np.sum(preds[0])) # sum it up! Should be 1\n",
    "## [9.9999988e-01 1.3509347e-07 6.7064638e-16]\n",
    "## 1.0\n",
    "\n",
    "# Almost a perfect prediction\n",
    "# actual is left, predicted is top\n",
    "# names can be found by inspecting Y\n",
    "matrix = confusion_matrix(y.argmax(axis=1), preds.argmax(axis=1))\n",
    "print('matttttttttttttttt',matrix)\n",
    "## array([[50,  0,  0],\n",
    "##        [ 0, 46,  4],\n",
    "##        [ 0,  1, 49]])\n",
    "\n",
    "\n",
    "# more detail on how well things were predicted\n",
    "print(classification_report(y.argmax(axis=1), preds.argmax(axis=1)))\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Learn to predict each class against the other\n",
    "\n",
    "\n",
    "n_classes = 3 # number of class\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "plt.figure()\n",
    "lw = 2 # line_width\n",
    "ax=plt.axes()\n",
    "\n",
    "# Set color\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curve for ANN classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cff01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras>=2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdb164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
